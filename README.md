# ğŸ“¦ SmartBin: Intelligent Order Validation System
   

**SmartBin** is a Zero-Shot Computer Vision system designed to automate inventory verification in Amazon Fulfillment Centers. It validates whether the items in a customer order are physically present in a bin, accounting for quantity and occlusion.

-----

## ğŸ”— Live Demo

The application is deployed on Streamlit Cloud:
**(https://smart-bin-validatior-v2.streamlit.app/)**

-----

## ğŸ‘¥ Team Members

| Name | Roll Number |
| :--- | :--- | 
| **Chirunomula Vamshi Krishna Babu** | SE22UARI038 |
| **Narukulla Mokshitha** | SE22UARI111 |
| **Gopu Venkata Kaashith** | SE22UARI200 |
| **Thodupunury Vamshi Krishna** | SE22UARI198 |

-----

## ğŸ¯ Objectives & Problem Statement

The e-commerce industry faces a critical challenge in inventory management: **accurately identifying items in heavily occluded bins** to verify order fulfillment.

**Core Objectives Achieved:**

1.  **Order Validation:** Verifies if specific ordered items (ASINs) are present in the bin image.
2.  **Quantity Verification:** Validates if the count of visible items matches the order manifest.
3.  **Zero-Shot Scalability:** Identifies novel items without re-training, solving the "New SKU" problem.
4.  **Interactive UI:** A user-friendly web interface for warehouse operators to perform manual checks.

-----

## ğŸ—ï¸ Technical Architecture

We moved beyond traditional supervised training (which fails on new inventory) to a **Hybrid Zero-Shot Architecture**.

### 1\. Proposal Generation (YOLOv8-Seg)

  * **Model:** `yolov8x-seg` (Pre-trained on COCO).
  * **Role:** Acts as a "Class-Agnostic Object Locator." It identifies regions of interest (ROI) where *any* object exists, regardless of what it is.
  * **Configuration:** High sensitivity (`conf=0.01`) to detect objects even in corners or shadows.

### 2\. Semantic Verification (CLIP ViT-B/32)

  * **Model:** OpenAI CLIP (Contrastive Language-Image Pre-Training).
  * **Role:** Verifies the identity of the crops generated by YOLO.
  * **Logic:** It compares the visual features of the crop against the **Text Embedding** of the ordered item (e.g., "Nerf Super Soaker").
  * **Innovation:** We utilize **Prompt Ensembling** (averaging embeddings of multiple descriptions) to improve robustness against messy database text.

-----

## ğŸš€ Key Features

  * **ğŸ” Pure Zero-Shot Inference:** The system does not rely on a static database during inference. It can detect *any* object that can be described in English.
  * **âœï¸ Manual Entry Mode:** Operators can manually type a description (e.g., "Red Nike Shoes") and the system will instantly generate a detector for it.
  * **ğŸ›‘ Quantity Mismatch Flags:** The system compares `Detected Count` vs. `Ordered Quantity`. If a mismatch is found (due to occlusion), it flags the order as **"Incomplete / Partial Match"** for human review.
  * **ğŸ§¹ Anti-Hallucination Filters:** Implements a strict "Background Class" (filtering empty shelves/tape) and Confidence Thresholding (`0.20`) to prevent false positives.

-----

## ğŸ“Š Evaluation & Results

We evaluated the system on a random subset of 50 images from the **Amazon Bin Image Dataset** using the ground truth metadata.

| Metric | Score | Description |
| :--- | :--- | :--- |
| **Item Recall Rate** | **\~43%** | Percentage of ordered items successfully verified autonomously. |
| **Precision Strategy** | **High** | We prioritized *Precision* over Recall to minimize false positives. A "Match" is highly trustworthy. |

**Observation:** The primary limitation is **Physical Occlusion**. In bins with 5+ items, deeper items are often completely hidden from the camera view. Our system correctly identifies the visible top layer and flags the rest as "Missing/Occluded".

-----

## ğŸ’» Installation & Usage

### 1\. Clone the Repository

```bash
git clone https://github.com/YOUR_USERNAME/SmartBin-AI.git
cd SmartBin-AI
```

### 2\. Install Dependencies

```bash
pip install -r requirements.txt
```

*Note: This requires `torch` and `ultralytics`. The first run will automatically download the YOLO weights (\~100MB).*

### 3\. Run the Application

```bash
streamlit run streamlit_app/app.py
```

### 4\. How to Use

1.  **Select Input Method:** Choose "Search Database" or "Manual Entry".
2.  **Create Order:** Add items (Description + Quantity) to the manifest.
3.  **Upload Image:** Upload a bin image (`.jpg`).
4.  **Validate:** Click "Verify Order Integrity".
5.  **Review:** Check the status badges (âœ… MATCH / âŒ MISSING).

-----

## ğŸ“‚ Project Structure

```text
SMARTBIN/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ inference.py       # Core Zero-Shot Logic (YOLO + CLIP)
â”‚   â”œâ”€â”€ validate_bin.py    # Evaluation Script for Metrics
â”‚   â””â”€â”€ run_subset.py      # Artifact Generator
â”œâ”€â”€ streamlit_app/
â”‚   â””â”€â”€ app.py             # User Interface Code
â”œâ”€â”€ processed/
â”‚   â”œâ”€â”€ asin_text.json     # ASIN to Description Mapping
â”‚   â””â”€â”€ master_metadata.csv # Ground Truth Data
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ subset_results.json # Final Submission Artifact
â”œâ”€â”€ requirements.txt       # Python Dependencies
â””â”€â”€ README.md              # Project Documentation
```

-----

## ğŸ“œ Acknowledgments

  * **Dataset:** Amazon Bin Image Dataset (AWS Public Datasets).
  * **Models:** Ultralytics YOLOv8 and OpenAI CLIP.

